{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2a87c709",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fb3f3aaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reddit_incel_posts: 988061\n",
      "reddit_incelexit_posts: 111083\n",
      "reddit_braincels_posts: 2216973\n",
      "Unique users in each dataset:\n",
      "reddit_incel: 29877\n",
      "reddit_incelexit: 4005\n",
      "reddit_braincels: 69303\n",
      "Total unique users across all datasets: 101200\n",
      "Total length of all datasets combined: 3316117\n",
      "Total unique users across all datasets: 101200\n",
      "Total length of all datasets combined: 3316117\n"
     ]
    }
   ],
   "source": [
    "# ---- Load the four main tables (TSV) ----\n",
    "#incels_is_comments   = pd.read_csv(\"data/incels.is_AllComments.anon\",           sep=\"\\t\", encoding=\"utf-8\", on_bad_lines=\"skip\")\n",
    "reddit_incel   = pd.read_csv(\"data/reddit-incel-posts.anon.txt\",          sep=\"\\t\", encoding=\"utf-8\", dtype = str)\n",
    "reddit_incelexit = pd.read_csv(\"data/reddit-IncelExit-posts.anon.txt\",          sep=\"\\t\", encoding=\"utf-8\", engine=\"python\", quoting=3, on_bad_lines=\"skip\", dtype=str)\n",
    "#saidit_incel_posts   = pd.read_csv(\"data/saidit-incel-posts.anon.txt\",          sep=\"\\t\", encoding=\"utf-8\", on_bad_lines=\"skip\")\n",
    "reddit_braincels   = pd.read_csv(\"data/reddit-braincels-posts.anon.txt\",          sep=\"\\t\", encoding=\"utf-8\", on_bad_lines=\"skip\", dtype=str)\n",
    "\n",
    "reddit_braincels = reddit_braincels.iloc[1:].reset_index(drop=True)\n",
    "\n",
    "# Optional: keep them in a dict for easy access\n",
    "dfs = {\n",
    "    #\"incels_is_comments\": incels_is_comments,\n",
    "    \"reddit_incel\": reddit_incel,\n",
    "    \"reddit_incelexit\": reddit_incelexit,\n",
    "    #\"saidit_incel_posts\": saidit_incel_posts,\n",
    "    \"reddit_braincels\": reddit_braincels\n",
    "}\n",
    "\n",
    "# streamline column names \n",
    "colnames = [\"link\", \"comment_id\", \"user_id\", \"parent\", \"timestamp\", \"title\", \"text\"]\n",
    "for name, df in dfs.items():\n",
    "    df.columns = colnames\n",
    "\n",
    "# Quick peek so you can see they loaded\n",
    "for name, df in dfs.items():\n",
    "    print(f\"{name}_posts: {df.shape[0]}\")\n",
    "    #display(df.head(10))\n",
    "\n",
    "print(\"Unique users in each dataset:\")\n",
    "for name, df in dfs.items():\n",
    "    print(f\"{name}: {len(df['user_id'].unique())}\")\n",
    "\n",
    "#total unique users across all datasets\n",
    "all_users = pd.concat([df['user_id'] for df in dfs.values()]).unique()\n",
    "print(f\"Total unique users across all datasets: {len(all_users)}\")\n",
    "\n",
    "#total length of all datasets combined \n",
    "total_length = sum(df.shape[0] for df in dfs.values())\n",
    "print(f\"Total length of all datasets combined: {total_length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4bdc59a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Renato Thieleke\\AppData\\Local\\Temp\\ipykernel_51364\\1574897855.py:5: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  valid_posts_incelexit['timestamp'] = pd.to_datetime(df['timestamp'], unit='s', errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Posts with valid link in IncelExit dataset: 110990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Renato Thieleke\\AppData\\Local\\Temp\\ipykernel_51364\\1574897855.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  valid_posts_incelexit['timestamp'] = pd.to_datetime(df['timestamp'], unit='s', errors='coerce')\n",
      "C:\\Users\\Renato Thieleke\\AppData\\Local\\Temp\\ipykernel_51364\\1574897855.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  valid_posts_incelexit.sort_values('timestamp', inplace=True)\n",
      "C:\\Users\\Renato Thieleke\\AppData\\Local\\Temp\\ipykernel_51364\\1574897855.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  valid_posts_incelexit[\"Original File Source\"] = \"r/IncelExit\"\n"
     ]
    }
   ],
   "source": [
    "valid_posts_incelexit_posts_idx = reddit_incelexit['link'].str.contains(r'r/IncelExit')\n",
    "\n",
    "valid_posts_incelexit = reddit_incelexit[valid_posts_incelexit_posts_idx]\n",
    "\n",
    "valid_posts_incelexit['timestamp'] = pd.to_datetime(df['timestamp'], unit='s', errors='coerce')\n",
    "valid_posts_incelexit.sort_values('timestamp', inplace=True)\n",
    "\n",
    "valid_posts_incelexit[\"Original File Source\"] = \"r/IncelExit\"\n",
    "\n",
    "print('Posts with valid link in IncelExit dataset:', valid_posts_incelexit_posts_idx.sum())\n",
    "#valid_posts_incelexit.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2126bc68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Renato Thieleke\\AppData\\Local\\Temp\\ipykernel_51364\\2730981505.py:21: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  valid_posts_incels['timestamp'] = pd.to_datetime(df['timestamp'], unit='s', errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users r/Incel:  29877\n",
      "Number of posts r/Incel: 988244\n"
     ]
    }
   ],
   "source": [
    "input_path = \"data/reddit-incel-posts.anon.txt\"\n",
    "output_path = \"data/reddit-incel-posts_with_quotes.txt\"\n",
    "\n",
    "#adding quotation marks at the end of each\n",
    "with open(input_path, encoding=\"utf-8\", errors=\"ignore\") as f_in, \\\n",
    "     open(output_path, \"w\", encoding=\"utf-8\", newline=\"\") as f_out:\n",
    "    for line in f_in:\n",
    "        if line.count('\"') % 2 != 0:\n",
    "            line = line.rstrip(\"\\n\") + '\"\\n'\n",
    "        f_out.write(line)\n",
    "\n",
    "valid_posts_incels = pd.read_csv(\n",
    "    output_path,\n",
    "    sep=\"\\t\",\n",
    "    encoding=\"utf-8\",\n",
    "    dtype=str,\n",
    "    header=None,\n",
    "    names=colnames\n",
    ")\n",
    "\n",
    "valid_posts_incels['timestamp'] = pd.to_datetime(df['timestamp'], unit='s', errors='coerce')\n",
    "valid_posts_incels.sort_values('timestamp', inplace=True)\n",
    "\n",
    "valid_posts_incels[\"Original File Source\"] = \"r/Incel\"\n",
    "\n",
    "print('Number of users r/Incel: ', len(valid_posts_incels['user_id'].unique()))\n",
    "print(\"Number of posts r/Incel:\", len(valid_posts_incels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "da1002cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Renato Thieleke\\AppData\\Local\\Temp\\ipykernel_51364\\1459181945.py:29: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  valid_posts_braincels['timestamp'] = pd.to_datetime(df['timestamp'], unit='s', errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users r/Braincel:  75267\n",
      "Number of posts r/Braincel:  2408121\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "input_path = \"data/reddit-braincels-posts.anon.txt\"\n",
    "output_path = \"data/reddit-braincels-posts_with_quotes.txt\"\n",
    "\n",
    "#adding quotation marks at the end of each\n",
    "with open(input_path, encoding=\"utf-8\", errors=\"ignore\") as f_in, \\\n",
    "     open(output_path, \"w\", encoding=\"utf-8\", newline=\"\") as f_out:\n",
    "    for line in f_in:\n",
    "        if line.count('\"') % 2 != 0:\n",
    "            line = line.rstrip(\"\\n\") + '\"\\n'\n",
    "        f_out.write(line)\n",
    "\n",
    "valid_posts_braincels = pd.read_csv(\n",
    "    \"data/reddit-braincels-posts_with_quotes.txt\",\n",
    "    sep=\"\\t\",\n",
    "    encoding=\"utf-8\",\n",
    "    engine=\"python\",\n",
    "    quoting=csv.QUOTE_NONE,\n",
    "    escapechar=\"\\\\\",\n",
    "    header=0,\n",
    "    names=colnames,\n",
    "    usecols=[0,1,2,3,4,5,6],\n",
    "    dtype=str,\n",
    "    na_filter=False,\n",
    "    keep_default_na=False,\n",
    "    on_bad_lines=\"warn\", \n",
    ")\n",
    "\n",
    "valid_posts_braincels['timestamp'] = pd.to_datetime(df['timestamp'], unit='s', errors='coerce')\n",
    "valid_posts_braincels.sort_values('timestamp', inplace=True)\n",
    "\n",
    "valid_posts_braincels[\"Original File Source\"] = \"r/Braincels\"\n",
    "\n",
    "print('Number of users r/Braincel: ', len(valid_posts_braincels['user_id'].unique()))\n",
    "print('Number of posts r/Braincel: ', len(valid_posts_braincels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "90561693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3507355, 8)\n",
      "(3098242, 8)\n",
      "(3098242, 8)\n",
      "(3098242, 9)\n",
      "(3098242, 9)\n"
     ]
    }
   ],
   "source": [
    "#Create compiled dataset\n",
    "reddit_dataset_compiled = pd.concat([valid_posts_incels, valid_posts_incelexit, valid_posts_braincels])\n",
    "print(reddit_dataset_compiled.shape)\n",
    "\n",
    "#dropping rows for identified deleted user and posts\n",
    "reddit_dataset_compiled = reddit_dataset_compiled[reddit_dataset_compiled['user_id'] != '924980486.069293']\n",
    "reddit_dataset_compiled_clean = reddit_dataset_compiled[reddit_dataset_compiled['title'] != '924980486.069293'] \n",
    "\n",
    "print(reddit_dataset_compiled_clean.shape)\n",
    "\n",
    "#Create column with the first subreddit each user posted in based on timestamp\n",
    "first_posts = reddit_dataset_compiled_clean.sort_values('timestamp').groupby('user_id').first()['Original File Source'].reset_index()\n",
    "first_posts.columns = ['user_id', 'Original User Source']\n",
    "\n",
    "reddit_dataset_compiled_clean = reddit_dataset_compiled_clean.merge(first_posts, on='user_id', how='left')\n",
    "print(reddit_dataset_compiled_clean.shape)\n",
    "\n",
    "#Export to csv\n",
    "reddit_dataset_compiled_clean.to_csv(\"data/reddit_dataset_compiled_clean.csv\", sep=',', index=False, encoding='utf-8')\n",
    "save_path = \"data/reddit_dataset_compiled_clean.csv\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
